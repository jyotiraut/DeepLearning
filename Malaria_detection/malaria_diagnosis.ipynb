{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-60IZfc_5bW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D,Dense,InputLayer,Flatten,BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError,BinaryAccuracy,TruePositives,FalsePositives,TrueNegatives,FalseNegatives,Precision,Recall,AUC\n",
        "from tensorflow.keras.losses import MeanSquaredError,Huber,MeanAbsoluteError,BinaryCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7bPcGEsAH4l"
      },
      "outputs": [],
      "source": [
        "dataset,dataset_info = tfds.load('malaria',with_info=True,as_supervised=True,shuffle_files=True,split=['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGMzmsTyE3PQ"
      },
      "outputs": [],
      "source": [
        "TRAIN_RATIO = 0.8\n",
        "TEST_RATIO = 0.1\n",
        "VAL_RATIO = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OS5D1V5AYQk"
      },
      "outputs": [],
      "source": [
        "def split(dataset,TRAIN_RATIO,TEST_RATIO,VAL_RATIO):\n",
        "\n",
        "  DATASET_SIZE = len(dataset)\n",
        "\n",
        "  train_dataset = dataset.take(int(TRAIN_RATIO * DATASET_SIZE))\n",
        "\n",
        "  val_test_dataset = dataset.skip(int(TRAIN_RATIO * DATASET_SIZE))\n",
        "\n",
        "\n",
        "  val_dataset = val_test_dataset.take(int(VAL_RATIO * DATASET_SIZE))\n",
        "\n",
        "\n",
        "  test_dataset = val_test_dataset.skip(int(VAL_RATIO * DATASET_SIZE))\n",
        "\n",
        "  return train_dataset,test_dataset,val_dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJPRKVL2BWIV",
        "outputId": "d7fb1d70-5127-4fff-82ba-c19005c85ca8"
      },
      "outputs": [],
      "source": [
        "train_dataset,test_dataset,val_dataset = split(dataset[0],TRAIN_RATIO,TEST_RATIO,VAL_RATIO)\n",
        "print(list(train_dataset.take(1).as_numpy_iterator()))\n",
        "print(list(test_dataset.take(1).as_numpy_iterator()))\n",
        "print(list(val_dataset.take(1).as_numpy_iterator()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_s9nNbBHeSb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQxiPq9HHi7S"
      },
      "source": [
        "Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "xGypc2uCHn3A",
        "outputId": "cad764e9-6c6f-4e28-b32a-40a4d35efa0f"
      },
      "outputs": [],
      "source": [
        "for i,(image,label) in enumerate(train_dataset.take(16)):\n",
        "  ax = plt.subplot(4,4,i+1)\n",
        "  plt.imshow(image)\n",
        "  plt.title(dataset_info.features['label'].int2str(label))\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VrcD67TIH0ex",
        "outputId": "980bf32d-5084-45dd-82c2-00f8d67a7fe8"
      },
      "outputs": [],
      "source": [
        "dataset_info.features['label'].int2str(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wybO2b7KJ4Bf"
      },
      "source": [
        "Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBIVaPW8LQ9P"
      },
      "outputs": [],
      "source": [
        "IM_SIZE = 224\n",
        "def resize_rescale(image,label):\n",
        "  return tf.image.resize(image,(IM_SIZE,IM_SIZE))/255.0,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjO_SUEgL4H9"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(resize_rescale)\n",
        "val_dataset = val_dataset.map(resize_rescale)\n",
        "test_dataset = test_dataset.map(resize_rescale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfz8GfkiJ6c0",
        "outputId": "832d2d29-2963-4cfa-b1d1-8d05971fdde2"
      },
      "outputs": [],
      "source": [
        "for image,label in train_dataset.take(1):\n",
        "  print(image,label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWNUCS7lNLl_"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size=8,reshuffle_each_iteration=True,).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgmsFJFtWc8w"
      },
      "outputs": [],
      "source": [
        "\n",
        "val_dataset = val_dataset.shuffle(buffer_size=8,reshuffle_each_iteration=True,).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LLR0SWGWdQP",
        "outputId": "0727c741-0675-492c-d41a-741637a64749"
      },
      "outputs": [],
      "source": [
        "val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAU66Ts1W2vE",
        "outputId": "3cbbbcc1-f09b-4ead-da7b-10d843317eda"
      },
      "outputs": [],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "BxVGMwDDxcY6",
        "outputId": "ac76744e-6eb3-4d05-b5c1-0766b6330c4e"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape=(IM_SIZE,IM_SIZE,3)),\n",
        "    Conv2D(filters = 6, kernel_size = 3, strides=1,padding='valid',activation='relu'),\n",
        "     BatchNormalization(),\n",
        "    MaxPool2D(pool_size=2,strides=1),\n",
        "\n",
        "\n",
        "\n",
        "    Conv2D(filters = 16, kernel_size = 5, strides=1,padding='valid',activation='relu'),\n",
        "     BatchNormalization(),\n",
        "    MaxPool2D(pool_size=2,strides=2),\n",
        "    Flatten(),\n",
        "    Dense(100, activation = \"relu\"),\n",
        "    Dense(10, activation = \"relu\"),\n",
        "    Dense(1, activation = \"sigmoid\"),\n",
        "\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnYc4GK2T9SC"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.1),\n",
        "              loss = BinaryCrossentropy(),\n",
        "              metrics = ['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, validation_data = val_dataset,epochs = 20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "nT6aYu5zUj-F",
        "outputId": "3bd4a489-2912-4e32-a6b7-7c0e13701c78"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_loss','val_loss'],loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "2_gKd90oVTzh",
        "outputId": "b10e46b0-c3c7-4236-dc1b-adb161628b1b"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model_Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_accuracy','val_accuracy'],loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj8IbAdefGgI"
      },
      "source": [
        "Model Evaluation and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npDm6grwfRPj"
      },
      "outputs": [],
      "source": [
        "test_dataset = test_dataset.batch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgwhQ4uzfFAs",
        "outputId": "941e2788-2314-4813-9571-a0cfd4847a4a"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z020xceAflUN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2bVkXCDfXQF"
      },
      "outputs": [],
      "source": [
        "def parasite_or_not(x):\n",
        "  if(x<0.5):\n",
        "    return str(\"P\")\n",
        "  else:\n",
        "    return str(\"U\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "JaxRxHcXf4Rr",
        "outputId": "3336a48a-df33-4fce-9eab-12c309fe4441"
      },
      "outputs": [],
      "source": [
        "parasite_or_not(model.predict(test_dataset.take(1))[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "abltxdhRgFG2",
        "outputId": "8fbf33e2-7fbe-4347-a91a-8a0edbfcbbcd"
      },
      "outputs": [],
      "source": [
        "for i,(image,label) in enumerate(test_dataset.take(9)):\n",
        "  ax = plt.subplot(3,3,i+1)\n",
        "  plt.imshow(image[0])\n",
        "  plt.title(str(parasite_or_not(label.numpy()[0])) + \":\" + str(parasite_or_not(model.predict(image)[0][0])))\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "func_input = Input(shape=(IM_SIZE,IM_SIZE,3),name = 'Input Image')\n",
        "\n",
        "x = Conv2D(filters = 6, kernel_size = 3, strides=1,padding='valid',activation='relu')(func_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=2,strides=1)(x)\n",
        "\n",
        "x = Conv2D(filters = 16, kernel_size = 5, strides=1,padding='valid',activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=2,strides=2)(x)\n",
        "\n",
        "\n",
        "output = Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "\n",
        "feature_extractor_model = Model(func_input,output,name = \"feature_extractor\")\n",
        "\n",
        "feature_extractor_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_extractor_sequential_model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape=(IM_SIZE,IM_SIZE,3)),\n",
        "    Conv2D(filters = 6, kernel_size = 3, strides=1,padding='valid',activation='relu'),\n",
        "     BatchNormalization(),\n",
        "    MaxPool2D(pool_size=2,strides=1),\n",
        "\n",
        "\n",
        "\n",
        "    Conv2D(filters = 16, kernel_size = 5, strides=1,padding='valid',activation='relu'),\n",
        "     BatchNormalization(),\n",
        "    MaxPool2D(pool_size=2,strides=2),\n",
        "    \n",
        "])\n",
        "\n",
        "feature_extractor_sequential_model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "func_input = Input(shape=(IM_SIZE,IM_SIZE,3),name = 'Input Image')\n",
        "\n",
        "x = feature_extractor_model(func_input)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(100, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dense(10, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "func_output = Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "\n",
        "lenet_model_func = Model(func_input,func_output, name = 'Lenet Model')\n",
        "\n",
        "lenet_model_func.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "func_input = Input(shape=(IM_SIZE,IM_SIZE,3),name = 'Input Image')\n",
        "\n",
        "x = feature_extractor_model(func_input)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(100, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dense(10, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "func_output = Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "\n",
        "lenet_model_func = Model(func_input,func_output, name = 'Lenet Model')\n",
        "\n",
        "lenet_model_func.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = [TruePositives(name=\"tp\"),FalsePositives(name=\"fp\"),TrueNegatives(name=\"tn\"),FalseNegatives(name=\"fn\"),BinaryAccuracy(name=\"accuracy\"),Precision(name=\"precision\"),Recall(name=\"recall\"),AUC(name=\"auc\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lenet_model_func.compile(optimizer=Adam(learning_rate=0.1),\n",
        "              loss = BinaryCrossentropy(),\n",
        "              metrics = metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = lenet_model_func.fit(train_dataset, validation_data = val_dataset,epochs = 20, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Subclassing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FeatureExtractor(Layer):\n",
        "    def __init__(self, filters, kernel_size, strides, padding, activation, pool_size):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "\n",
        "        self.conv2d_1 = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, \n",
        "                               padding=padding, activation=activation)\n",
        "        self.batch_1 = BatchNormalization()\n",
        "        self.pool_1 = MaxPool2D(pool_size=pool_size, strides=2*strides)\n",
        "\n",
        "        self.conv2d_2 = Conv2D(filters=filters * 2, kernel_size=kernel_size, strides=strides, \n",
        "                               padding=padding, activation=activation)\n",
        "        self.batch_2 = BatchNormalization()\n",
        "        self.pool_2 = MaxPool2D(pool_size=pool_size, strides=2*strides)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv2d_1(x)\n",
        "        x = self.batch_1(x)\n",
        "        x = self.pool_1(x)\n",
        "\n",
        "        x = self.conv2d_2(x)\n",
        "        x = self.batch_2(x)\n",
        "        x = self.pool_2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "feature_sub_classed = FeatureExtractor(8,3,1,'valid','relu',2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "func_input = Input(shape=(IM_SIZE,IM_SIZE,3),name = 'Input Image')\n",
        "\n",
        "x = feature_sub_classed(func_input)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(100, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dense(10, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "func_output = Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "\n",
        "lenet_model_func = Model(func_input,func_output, name = 'Lenet Model')\n",
        "\n",
        "lenet_model_func.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LenetModel(Model):\n",
        "    def __init__(self):\n",
        "        super(LenetModel, self).__init__()\n",
        "\n",
        "        \n",
        "        self.feature_extractor = FeatureExtractor(8, 3, 1, \"valid\", \"relu\", 2)\n",
        "        self.flatten = Flatten()\n",
        "        self.dense_1 = Dense(100, activation=\"relu\")\n",
        "        self.batch_1 = BatchNormalization()\n",
        "        self.dense_2 = Dense(10, activation=\"relu\")\n",
        "        self.batch_2 = BatchNormalization()\n",
        "        self.dense_3 = Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x = self.feature_extractor(x, training=training)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense_1(x)\n",
        "        x = self.batch_1(x, training=training)\n",
        "        x = self.dense_2(x)\n",
        "        x = self.batch_2(x, training=training)\n",
        "        return self.dense_3(x)\n",
        "\n",
        "\n",
        "lenet_sub_classed = LenetModel() \n",
        "lenet_sub_classed(tf.zeros((1, 224, 224, 3))) \n",
        "lenet_sub_classed.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lenet_sub_classed.compile(optimizer=Adam(learning_rate=0.1),\n",
        "              loss = BinaryCrossentropy(),\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = lenet_sub_classed.fit(train_dataset, validation_data = val_dataset,epochs = 20, verbose=1)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyDense(Layer):\n",
        "    def __init__(self, output_units):\n",
        "        super(MyDense, self).__init__()\n",
        "        self.output_units = output_units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "    \n",
        "        input_dim = input_shape[-1]\n",
        "        \n",
        "      \n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_dim, self.output_units),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name=\"weights\"\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.output_units,),\n",
        "            initializer='zeros',\n",
        "            trainable=True,\n",
        "            name=\"bias\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "IM_SIZE = 224\n",
        "func_input = Input(shape=(IM_SIZE, IM_SIZE, 3), name='Input Image')\n",
        "\n",
        "x = feature_sub_classed(func_input)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = MyDense(100)(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = MyDense(10)(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "func_output = Dense(1, activation='sigmoid')(x)  # Keep this as-is\n",
        "\n",
        "lenet_model_func = Model(func_input, func_output, name='Lenet Model')\n",
        "\n",
        "lenet_model_func.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
